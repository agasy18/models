{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from skimage.transform import resize\n",
    "import json\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......\n",
      "\u001b[32mLoading:\u001b[0m \n",
      "\u001b[1A\u001b[K\u001b[32mLoading:\u001b[0m 0 packages loaded\n",
      "\u001b[1A\u001b[K\u001b[32mAnalyzing:\u001b[0m 17 targets (3 packages loaded)\n",
      "\u001b[1A\u001b[K\u001b[32mAnalyzing:\u001b[0m 17 targets (4 packages loaded)\n",
      "    currently loading: @local_config_cc//\n",
      "\u001b[1A\u001b[K\u001b[32mAnalyzing:\u001b[0m 17 targets (6 packages loaded)\n",
      "    currently loading: tools/defaults\n",
      "\u001b[1A\u001b[K\u001b[32mINFO: \u001b[0mAnalysed 17 targets (17 packages loaded).\n",
      "\u001b[32mBuilding:\u001b[0m no action\n",
      "\u001b[1A\u001b[K\u001b[32mINFO: \u001b[0mFound 17 targets...\n",
      "\u001b[32mBuilding:\u001b[0m no action\n",
      "\u001b[1A\u001b[K\u001b[32m[24 / 25]\u001b[0m [-----] BazelWorkspaceStatusAction stable-status.txt\n",
      "\u001b[1A\u001b[K\u001b[32mINFO: \u001b[0mElapsed time: 1.196s, Critical Path: 0.01s\n",
      "\u001b[32m[25 / 25]\u001b[0m no action\n",
      "\u001b[1A\u001b[K\u001b[32mINFO:\u001b[0m Build completed successfully, 1 total action\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!bazel build -c opt //im2txt/..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, 'bazel-bin/im2txt/run_inference.runfiles/im2txt/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from im2txt import configuration\n",
    "from im2txt.inference_utils import caption_generator\n",
    "from im2txt.inference_utils import vocabulary\n",
    "from im2txt import show_and_tell_model\n",
    "from im2txt.inference_utils import inference_wrapper_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\r\n",
      "\u001b[0m\u001b[01;34meval\u001b[0m/\r\n",
      "events.out.tfevents.1524214695.aghasy-gpu\r\n",
      "graph.pbtxt\r\n",
      "model.ckpt-1000000.data-00000-of-00001\r\n",
      "model.ckpt-1000000.index\r\n",
      "model.ckpt-1000000.meta\r\n",
      "model.ckpt-987898.data-00000-of-00001\r\n",
      "model.ckpt-987898.index\r\n",
      "model.ckpt-987898.meta\r\n",
      "model.ckpt-991595.data-00000-of-00001\r\n",
      "model.ckpt-991595.index\r\n",
      "model.ckpt-991595.meta\r\n",
      "model.ckpt-995243.data-00000-of-00001\r\n",
      "model.ckpt-995243.index\r\n",
      "model.ckpt-995243.meta\r\n",
      "model.ckpt-998920.data-00000-of-00001\r\n",
      "model.ckpt-998920.index\r\n",
      "model.ckpt-998920.meta\r\n"
     ]
    }
   ],
   "source": [
    "ls /hdd/train/im2txt+ssd/3/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '/hdd/train/im2txt+ssd-archive/ssd-ext/model.ckpt-591574'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceWrapper(inference_wrapper_base.InferenceWrapperBase):\n",
    "    \"\"\"Model wrapper class for performing inference with a ShowAndTellModel.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(InferenceWrapper, self).__init__()\n",
    "        self.fetches = {}\n",
    "        self.post_feed_image = lambda result: 0\n",
    "    \n",
    "    def build_model(self, model_config):\n",
    "        model = show_and_tell_model.ShowAndTellModel(model_config, mode=\"inference\")\n",
    "        model.build()\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    \n",
    "    def feed_image(self, sess, encoded_image):\n",
    "        self.fetches['initial_state'] = tf.get_default_graph().get_tensor_by_name('lstm/initial_state:0')\n",
    "        result = sess.run(fetches=self.fetches,\n",
    "                                 feed_dict={\"image_feed:0\": encoded_image})\n",
    "        self.post_feed_image(result)\n",
    "        return result['initial_state']\n",
    "\n",
    "    def inference_step(self, sess, input_feed, state_feed):\n",
    "        softmax_output, state_output = sess.run(\n",
    "            fetches=[\"softmax:0\", \"lstm/state:0\"],\n",
    "            feed_dict={\n",
    "                \"input_feed:0\": input_feed,\n",
    "                \"lstm/state_feed:0\": state_feed,\n",
    "            })\n",
    "        return softmax_output, state_output, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building model.\n"
     ]
    }
   ],
   "source": [
    "model = InferenceWrapper()\n",
    "config = configuration.ModelConfig()\n",
    "restore_fn = model.build_graph_from_config(config, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_uninitialized(sess):\n",
    "    global_vars          = tf.global_variables()\n",
    "    is_not_initialized   = sess.run([tf.is_variable_initialized(var) for var in global_vars])\n",
    "    not_initialized_vars = [v for (v, f) in zip(global_vars, is_not_initialized) if not f]\n",
    "    if not_initialized_vars:\n",
    "        print 'Not initalized varibles are: ', [str(i.name) for i in not_initialized_vars]\n",
    "        # from tensorflow.python.tools.inspect_checkpoint import print_tensors_in_checkpoint_file\n",
    "        # print_tensors_in_checkpoint_file(checkpoint_path, all_tensors=True, tensor_name='')\n",
    "    assert not not_initialized_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model from checkpoint: /hdd/train/im2txt+ssd-archive/ssd-ext/model.ckpt-591574\n",
      "INFO:tensorflow:Restoring parameters from /hdd/train/im2txt+ssd-archive/ssd-ext/model.ckpt-591574\n",
      "INFO:tensorflow:Successfully loaded checkpoint: model.ckpt-591574\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    restore_fn(sess)\n",
    "    test_uninitialized(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '..')\n",
    "sys.path.insert(0, '../slim/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from object_detection.utils import ops as utils_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ..; protoc object_detection/protos/*.proto --python_out=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../object_detection/utils/visualization_utils.py:25: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n",
      "    \"__main__\", fname, loader, pkg_name)\n",
      "  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\n",
      "    exec code in run_globals\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py\", line 497, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py\", line 1073, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py\", line 2724, in run_cell\n",
      "    self.events.trigger('post_run_cell')\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/events.py\", line 74, in trigger\n",
      "    func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/ipykernel/pylab/backend_inline.py\", line 164, in configure_once\n",
      "    activate_matplotlib(backend)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/IPython/core/pylabtools.py\", line 315, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/pyplot.py\", line 231, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/__init__.py\", line 1422, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements\n"
     ]
    }
   ],
   "source": [
    "sys.path.insert(0, '../object_detection')\n",
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_LABELS = os.path.abspath('../object_detection/data/mscoco_label_map.pbtxt')\n",
    "NUM_CLASSES = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map  = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensor = tf.get_default_graph().get_tensor_by_name('image_feed:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detection_tensors():\n",
    "    ops = tf.get_default_graph().get_operations()\n",
    "    all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "    tensor_dict = {}\n",
    "    for key in [\n",
    "            'num_detections', 'detection_boxes', 'detection_scores',\n",
    "            'detection_classes', 'detector_image', 'decode/DecodeJpeg'\n",
    "    ]:\n",
    "        tensor_name = key + ':0'\n",
    "        if tensor_name in all_tensor_names:\n",
    "            tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "                    tensor_name)\n",
    "    return tensor_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_detection_result(output_dict):\n",
    "    # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "    image_np = output_dict['decode/DecodeJpeg']\n",
    "    # Visualization of the results of a detection.\n",
    "    image_np = np.array(image_np).astype(np.uint8)[:,:,:3]\n",
    "#     image_np = resize(image_np, (640, int(640.0 / image_np.shape[0] *image_np.shape[1]), 3))\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "         image_np,\n",
    "         output_dict['detection_boxes'][0],\n",
    "         output_dict['detection_classes'][0].astype(np.uint8),\n",
    "         output_dict['detection_scores'][0],\n",
    "         category_index,\n",
    "         instance_masks=None,\n",
    "         use_normalized_coordinates=True,\n",
    "         line_thickness=min(image_np.shape[:-1]) / 100)\n",
    "    plt.figure(figsize=IMAGE_SIZE)\n",
    "    plt.imshow(image_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fetches = get_detection_tensors()\n",
    "# model.post_feed_image = draw_detection_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing vocabulary from file: /hdd/train/im2txt-mid/word_counts.txt\n",
      "INFO:tensorflow:Created vocabulary with 11520 words\n"
     ]
    }
   ],
   "source": [
    "vocab_file = '/hdd/train/im2txt-mid/word_counts.txt'\n",
    "vocab = vocabulary.Vocabulary(vocab_file)\n",
    "generator = caption_generator.CaptionGenerator(model, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_file = '../../../coco-caption/annotations/captions_val2014.json'\n",
    "with open(annotation_file) as f:\n",
    "    js = json.load(f)\n",
    "images = [(a['id'], a['file_name']) for a in js['images']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = '/hdd/datasets/mscoco/dataset/mscoco/val2014/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_words_choses = [[vocab.word_to_id(k)] * v for k, v in vocab.vocab.items()]\n",
    "random_words_choses = [x for x in random_words_choses for i in x]\n",
    "vocab.end_id in random_words_choses and random_words_choses.remove(vocab.end_id)\n",
    "vocab.start_id in random_words_choses and random_words_choses.remove(vocab.start_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model from checkpoint: /hdd/train/im2txt+ssd-archive/ssd-ext/model.ckpt-591574\n",
      "INFO:tensorflow:Restoring parameters from /hdd/train/im2txt+ssd-archive/ssd-ext/model.ckpt-591574\n",
      "INFO:tensorflow:Successfully loaded checkpoint: model.ckpt-591574\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9100943a30cb4617b10a0c94067a12fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_annotations = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    restore_fn(sess)\n",
    "    for image_id, file_name in tqdm(images[:1000]):\n",
    "        with open(os.path.join(images_dir, file_name), 'r') as content_file:\n",
    "            content = content_file.read()\n",
    "        captions = generator.beam_search(sess, content)\n",
    "        for caption in captions:\n",
    "            sentence = [vocab.id_to_word(w) for w in caption.sentence[1:-1]]\n",
    "            sentence = \" \".join(sentence)\n",
    "            sentence = sentence.replace('<S>', '')\n",
    "            sentence = sentence.replace('  ', ' ').replace('  ', ' ').replace('  ', ' ')\n",
    "            sentence = sentence.replace('. .', '.').replace('..', '.').replace('. .', '.')\n",
    "            new_annotations.append(dict(image_id=image_id, caption=sentence, file_name=file_name))\n",
    "            break\n",
    "    with open(checkpoint_path + '.captions_result.json', 'w') as f:\n",
    "        json.dump(new_annotations, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_caption = '../../../coco-caption/'\n",
    "sys.path.insert(0, coco_caption)\n",
    "from pycocotools.coco import COCO\n",
    "from pycocoevalcap.eval import COCOEvalCap\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "import os\n",
    "import json\n",
    "from json import encoder\n",
    "encoder.FLOAT_REPR = lambda o: format(o, '.3f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Stanford CoreNLP.\r\n"
     ]
    }
   ],
   "source": [
    "# set up file names and pathes\n",
    "annFile=annotation_file\n",
    "resFile = checkpoint_path + '.captions_result.json'\n",
    "evalImgsFile = checkpoint_path + '.captions_evalImgs.json'\n",
    "evalFile = checkpoint_path + '.captions_eval.json'\n",
    "\n",
    "# download Stanford models\n",
    "!{coco_caption}/get_stanford_models.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:00.497129\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...     \n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# create coco object and cocoRes object\n",
    "coco = COCO(annFile)\n",
    "cocoRes = coco.loadRes(resFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenization...\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'reflen': 10371, 'guess': [10371, 9371, 8371, 7371], 'testlen': 10371, 'correct': [10371, 1532, 139, 17]}\n",
      "ratio: 1.0\n",
      "Bleu_1: 1.000\n",
      "Bleu_2: 0.404\n",
      "Bleu_3: 0.139\n",
      "Bleu_4: 0.050\n",
      "computing METEOR score...\n",
      "METEOR: 0.415\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.469\n",
      "computing CIDEr score...\n",
      "CIDEr: 1.102\n",
      "computing SPICE score...\n",
      "SPICE: 0.180\n"
     ]
    }
   ],
   "source": [
    "# create cocoEval object by taking coco and cocoRes\n",
    "cocoEval = COCOEvalCap(coco, cocoRes)\n",
    "\n",
    "# evaluate on a subset of images by setting\n",
    "# cocoEval.params['image_id'] = cocoRes.getImgIds()\n",
    "# please remove this line when evaluating the full validation set\n",
    "cocoEval.params['image_id'] = cocoRes.getImgIds()\n",
    "\n",
    "# evaluate results\n",
    "# SPICE will take a few minutes the first time, but speeds up due to caching\n",
    "cocoEval.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIDEr: 1.102\n",
      "Bleu_4: 0.050\n",
      "Bleu_3: 0.139\n",
      "Bleu_2: 0.404\n",
      "Bleu_1: 1.000\n",
      "ROUGE_L: 0.469\n",
      "METEOR: 0.415\n",
      "SPICE: 0.180\n"
     ]
    }
   ],
   "source": [
    "# print output evaluation scores\n",
    "for metric, score in cocoEval.eval.items():\n",
    "    print '%s: %.3f'%(metric, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ground truth captions\n",
      "A train traveling down tracks next to lights.\n",
      "A blue and silver train next to train station and trees.\n",
      "A blue train is next to a sidewalk on the rails.\n",
      "A passenger train pulls into a train station.\n",
      "A train coming down the tracks arriving at a station.\n",
      "\n",
      "\n",
      "generated caption (CIDEr score 1.1)\n",
      "lights. traveling next to tracks A down train\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: u'.//images/val2014/COCO_val2014_000000184321.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIOError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-2a3f3d864476>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadImgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgId\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s/images/%s/%s'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'val2014'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'file_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/skimage/io/_io.pyc\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, flatten, **plugin_args)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/skimage/io/manage_plugins.pyc\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m                                (plugin, kind))\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/skimage/io/_plugins/pil_plugin.pyc\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, dtype, img_num, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \"\"\"\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpil_to_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: u'.//images/val2014/COCO_val2014_000000184321.jpg'"
     ]
    }
   ],
   "source": [
    "# demo how to use evalImgs to retrieve low score result\n",
    "evals = [eva for eva in cocoEval.evalImgs if eva['CIDEr']<30]\n",
    "print 'ground truth captions'\n",
    "imgId = evals[0]['image_id']\n",
    "annIds = coco.getAnnIds(imgIds=imgId)\n",
    "anns = coco.loadAnns(annIds)\n",
    "coco.showAnns(anns)\n",
    "\n",
    "print '\\n'\n",
    "print 'generated caption (CIDEr score %0.1f)'%(evals[0]['CIDEr'])\n",
    "annIds = cocoRes.getAnnIds(imgIds=imgId)\n",
    "anns = cocoRes.loadAnns(annIds)\n",
    "coco.showAnns(anns)\n",
    "\n",
    "img = coco.loadImgs(imgId)[0]\n",
    "I = io.imread('%s/images/%s/%s'%('./','val2014',img['file_name']))\n",
    "plt.imshow(I)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot score histogram\n",
    "ciderScores = [eva['CIDEr'] for eva in cocoEval.evalImgs]\n",
    "plt.hist(ciderScores)\n",
    "plt.title('Histogram of CIDEr Scores', fontsize=20)\n",
    "plt.xlabel('CIDEr score', fontsize=20)\n",
    "plt.ylabel('result counts', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save evaluation results to ./results folder\n",
    "json.dump(cocoEval.evalImgs, open(evalImgsFile, 'w'))\n",
    "json.dump(cocoEval.eval,     open(evalFile, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "js['info']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
