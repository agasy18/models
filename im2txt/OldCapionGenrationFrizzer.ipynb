{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous HEAD position was 91c7b91... Variables defined in ExponentialMovingAverage need not to be shared. (#778)\r\n",
      "HEAD is now at 07827aa... Wording change\r\n"
     ]
    }
   ],
   "source": [
    "!git checkout HEAD~10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.12.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mLoading:\u001b[0m \n",
      "\u001b[1A\u001b[K\u001b[32mLoading:\u001b[0m 0 packages loaded\n",
      "\u001b[1A\u001b[K\u001b[32mINFO: \u001b[0mAnalysed 17 targets (0 packages loaded).\n",
      "\u001b[32mBuilding:\u001b[0m no action\n",
      "\u001b[1A\u001b[K\u001b[32mINFO: \u001b[0mFound 17 targets...\n",
      "\u001b[32mBuilding:\u001b[0m no action\n",
      "\u001b[1A\u001b[K\u001b[32m[0 / 6]\u001b[0m [-----] BazelWorkspaceStatusAction stable-status.txt\n",
      "\u001b[1A\u001b[K\u001b[32mINFO: \u001b[0mElapsed time: 0.191s, Critical Path: 0.00s\n",
      "\u001b[32m[1 / 1]\u001b[0m no action\n",
      "\u001b[1A\u001b[K\u001b[32mINFO:\u001b[0m Build completed successfully, 1 total action\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!bazel build -c opt //im2txt/..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, 'bazel-bin/im2txt/run_inference.runfiles/im2txt/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from im2txt import configuration\n",
    "from im2txt.inference_utils import caption_generator\n",
    "from im2txt.inference_utils import vocabulary\n",
    "from im2txt import show_and_tell_model\n",
    "from im2txt.inference_utils import inference_wrapper_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = '/hdd/models/im2txt_2016_10_05.1000000/model.ckpt-1000000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceWrapper(inference_wrapper_base.InferenceWrapperBase):\n",
    "    \"\"\"Model wrapper class for performing inference with a ShowAndTellModel.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(InferenceWrapper, self).__init__()\n",
    "        self.fetches = {}\n",
    "        self.st_custom_getter = None\n",
    "        self.post_feed_image = lambda: result \n",
    "    \n",
    "    def build_model(self, model_config):\n",
    "        model = show_and_tell_model.ShowAndTellModel(model_config, mode=\"inference\")\n",
    "        model.build()\n",
    "        return model\n",
    "    \n",
    "    def feed_image(self, sess, encoded_image):\n",
    "        self.fetches['initial_state'] = tf.get_default_graph().get_tensor_by_name('lstm/initial_state:0')\n",
    "        result = sess.run(fetches=self.fetches,\n",
    "                                 feed_dict={\"image_feed:0\": encoded_image})\n",
    "        self.post_feed_image(result)\n",
    "        return result['initial_state']\n",
    "\n",
    "    def inference_step(self, sess, input_feed, state_feed):\n",
    "        softmax_output, state_output = sess.run(\n",
    "            fetches=[\"softmax:0\", \"lstm/state:0\"],\n",
    "            feed_dict={\n",
    "                \"input_feed:0\": input_feed,\n",
    "                \"lstm/state_feed:0\": state_feed,\n",
    "            })\n",
    "        return softmax_output, state_output, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building model.\n",
      "WARNING:tensorflow:From bazel-bin/im2txt/run_inference.runfiles/im2txt/im2txt/ops/image_processing.py:95 in image_summary.: image_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.image. Note that tf.summary.histogram uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, the max_images argument was renamed to max_outputs.\n",
      "WARNING:tensorflow:From bazel-bin/im2txt/run_inference.runfiles/im2txt/im2txt/ops/image_processing.py:95 in image_summary.: image_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.image. Note that tf.summary.histogram uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, the max_images argument was renamed to max_outputs.\n",
      "WARNING:tensorflow:From bazel-bin/im2txt/run_inference.runfiles/im2txt/im2txt/ops/image_processing.py:95 in image_summary.: image_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.image. Note that tf.summary.histogram uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, the max_images argument was renamed to max_outputs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.ops.variables.Variable at 0x7fc62eb444d0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fc62eb44dd0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fc62ea56050>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fc62ea56a10>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fc62e9904d0>,\n",
       " <tensorflow.python.ops.variables.Variable at 0x7fc62e9900d0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = InferenceWrapper()\n",
    "config = configuration.ModelConfig()\n",
    "\n",
    "def _create_restore_fn(self, checkpoint_path, saver):\n",
    "    print \"Someting\"\n",
    "st_variables_map = {}\n",
    "\n",
    "def st_custom_getter(getter, name, shape, *args, **kwargs):\n",
    "    if name in st_variables_map:\n",
    "        return st_variables_map[name]\n",
    "    print('Restoring', name, shape)\n",
    "    kwargs['trainable'] = False\n",
    "    c = None\n",
    "    name = name_map.get(name) or name\n",
    "    if reader.has_tensor(name):\n",
    "        c = reader.get_tensor(name)\n",
    "    elif reader.has_tensor('InceptionV3/' + name):\n",
    "        c = reader.get_tensor('InceptionV3/' + name)\n",
    "    assert(c is not None)\n",
    "    \n",
    "    kwargs['initializer'] = tf.constant_initializer(c)\n",
    "\n",
    "    \n",
    "    v = getter(name, shape, *args, **kwargs)\n",
    "    st_variables_map[name]= v\n",
    "    return v\n",
    "\n",
    "st_variables = list(st_variables_map.values())\n",
    "\n",
    "# model.st_custom_getter = st_custom_getter\n",
    "\n",
    "restore_fn = model.build_graph_from_config(config, checkpoint_path)\n",
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b3698bc3da99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert(len(tf.trainable_variables()) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-db958c41f733>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchekpointvars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable_to_shape_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mst_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchekpointvars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchekpointvars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mst_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reader' is not defined"
     ]
    }
   ],
   "source": [
    "chekpointvars = list(reader.get_variable_to_shape_map().keys())\n",
    "set(st_variables).difference(set(chekpointvars)), set(chekpointvars).difference(set(st_variables)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_uninitialized(sess):\n",
    "    global_vars          = tf.global_variables()\n",
    "    is_not_initialized   = sess.run([tf.is_variable_initialized(var) for var in global_vars])\n",
    "    not_initialized_vars = [v for (v, f) in zip(global_vars, is_not_initialized) if not f]\n",
    "    if not_initialized_vars:\n",
    "        print ('Not initalized varibles are: ', [str(i.name) for i in not_initialized_vars])\n",
    "        # from tensorflow.python.tools.inspect_checkpoint import print_tensors_in_checkpoint_file\n",
    "        # print_tensors_in_checkpoint_file(checkpoint_path, all_tensors=True, tensor_name='')\n",
    "    assert not not_initialized_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model from checkpoint: /hdd/models/im2txt_2016_10_05.1000000/model.ckpt-1000000\n",
      "INFO:tensorflow:Successfully loaded checkpoint: model.ckpt-1000000\n",
      "INFO:tensorflow:Froze 766 variables.\n",
      "Converted 382 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    restore_fn(sess)\n",
    "    test_uninitialized(sess)\n",
    "    const_graph = tf.graph_util.convert_variables_to_constants(sess, tf.get_default_graph().as_graph_def(), [\n",
    "        'lstm/initial_state',\n",
    "        \"softmax\",\n",
    "        \"lstm/state\"\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_graph = os.path.join(os.path.dirname(checkpoint_path), 'const_' + os.path.basename(checkpoint_path) + '.pb')\n",
    "with tf.gfile.GFile(output_graph, \"wb\") as f:\n",
    "    f.write(const_graph.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 aghasy aghasy 143M Sep 11 21:59 /hdd/models/im2txt_2016_10_05.1000000/const_model.ckpt-1000000.pb\r\n"
     ]
    }
   ],
   "source": [
    "!ls -alh {output_graph} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Passing a `GraphDef` to the SummaryWriter is deprecated. Pass a `Graph` object instead, such as `sess.graph`.\n"
     ]
    }
   ],
   "source": [
    "writer = tf.summary.FileWriter(os.path.join(os.path.dirname(checkpoint_path),  'const_' + os.path.basename(checkpoint_path) + '.logdir'), graph_def=const_graph)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-0.12.1",
   "language": "python",
   "name": "tf-0.12.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
